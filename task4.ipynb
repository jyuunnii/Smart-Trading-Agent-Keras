{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smart Trading Agent\n",
    "In this notebook, we predict cryptocurrency transaction based on five pieces of data:\n",
    "- Timestamp (year-month-day hour:min:sec)\n",
    "- Price \n",
    "- Mid Price \n",
    "- Book Feature \n",
    "- Side (Sell / Buy)\n",
    "\n",
    "\n",
    "## Introduction\n",
    "In this tutorial we will use the popular Deep Learning library, Keras, and the visualization libraries Matplotlib and Seaborn to build a classifying simple model. \n",
    "The libraries Numpy and Pandas will help us along the way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Importing pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Reading the csv file into a pandas DataFrame\n",
    "data = pd.read_csv('data/2018-05-newtrade.csv')\n",
    "\n",
    "# Printing out the first 10 rows of our data\n",
    "data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualization\n",
    "We will now start thinking of which of these features we will use in our model.\n",
    "First let's make a plot of our data to see how it looks. \n",
    "To visualize our data, we will use matplotlib and seaborn.\n",
    "\n",
    "Intuitively, it makes sense that the price of BTC ('price') would play a big role in the customer consumption('side').\n",
    "Let's see if these hypotheses are correct:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "# Importing matplotlib, seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "x = data.price.values\n",
    "\n",
    "# Plotting the graphs\n",
    "sns.distplot(x, kde = True, rug = True)\n",
    "plt.title(\"Price Distribution Graph\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "sns.violinplot(x='side', y='price', data=data)\n",
    "plt.title(\"Price Violin Graph\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Unfortunately, it is a bit hard to visualize prices since we have a lot of different samples. \n",
    "\n",
    "There are some peek points around 0.99 and 1.015. At these points, trader bought or sold BTC at the highest price."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we can see that prices on both ends of the spectrum seem to fare better, but we need to get a closer look. We will 'bin-ify' the prices, grouping them to bins according to their value. So, ages closer together will appear as one and it will be easier to visualize.\n",
    "\n",
    "The function we will use will round the prices within a factor. We will use numpy."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "# Importing numpy\n",
    "import numpy as np\n",
    "\n",
    "# Function to help us scaling\n",
    "def make_bins(d, col, factor=2):\n",
    "    rounding = lambda x: np.around(x / factor)\n",
    "    d[col] = d[col].apply(rounding)\n",
    "    return d\n",
    "\n",
    "t = make_bins(data.copy(True), 'price', 100000)\n",
    "\n",
    "# Plotting the bar graphs\n",
    "sns.barplot(x='price', y='side', data = t)\n",
    "plt.title(\"Price Bar Graph\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "There doesn't seem to be much correlation to transaction rate.\n",
    "\n",
    "How about counts?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "# Plotting the bar graphs\n",
    "sns.countplot(x='price', data = t)\n",
    "plt.title(\"Price x Transaction Count Graph\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It seems more clear that trader usually make highest numbers of transactions around 9,900,000 won. \n",
    "The number of transactions grows proportionally to around 9,900,000 won, since then it decreases. It returns to growth by around 1,015,000 won, but its total counts are much smaller than before.\n",
    "\n",
    "### conclusion 1:\n",
    "Main trade price of May 2018 is about 9,900,000 won and most trades are under 10,500,000 won.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now to check the book feature:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "t = make_bins(data.copy(True), 'book_feature', 1000000)\n",
    "\n",
    "# Plotting the bar graphs\n",
    "sns.countplot(x='book_feature', data = t)\n",
    "plt.title(\"Book Feature x Transaction Count Graph1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "It shows a correlation of transaction counts with book features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plotting the bar graphs\n",
    "sns.countplot(x='book_feature',hue='side', data = t)\n",
    "plt.title(\"Book Feature x Transaction Count Graph2\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "same as both sides, buy and sell."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Something does seem to be going on with 'Book Feature'. When it's over zero, total transaction counts at those feature numbers start to decrease.\n",
    "Especially, the count numbers of 3 is more than twice the 8.\n",
    "\n",
    "## conclusion 2\n",
    "The latest roundup of information is that the trader usually make transactions at price from 9,900,000 won to 10,000,000 won. And those book-feature will be under 7,000,000 won with high possibility."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's try to think about transaction types separately. And this time, we will focus on transaction price under 10,000,000 won and book-feature under 7,000,000 won more specifically."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "datacopy = data[data['price'] <= 10000000]\n",
    "\n",
    "# Two conditions to extract a book-feature range\n",
    "top = datacopy['book_feature'] < 8000000\n",
    "bottom = datacopy['book_feature'] > 0\n",
    "datacopy = datacopy[top & bottom]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "In a narrow spectrum, let's see:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "c = make_bins(datacopy.copy(True), 'book_feature', 1000000)\n",
    "\n",
    "# Plotting the bar graphs\n",
    "sns.countplot(x='book_feature', hue='side', data = c)\n",
    "plt.title(\"Book Feature x Transaction Count Graph3\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The highest number of sells is around 1,000,000 won, on the other hand, the highest number of purchases is around 2,000,000 won.\n",
    "The second one of sells is around 3,000,000 won and one of purchases is also around 3,000,000 won.\n",
    "\n",
    "The trend line is decreasing on both graphs.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For the first time, let's consider about transaction time:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "datcopy = data\n",
    "datacopy['timestamp'] = datacopy['timestamp'].map(lambda x:x.split(' ')[1].split(':')[0].strip())   \n",
    "\n",
    "# Plotting the bar graphs\n",
    "sns.countplot(x='timestamp', data=datacopy)\n",
    "plt.title(\"Time x Transaction Count Graph\")\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Against our expectations, there doesn't seem to be much correlation to transaction time.\n",
    "\n",
    "## final conclusion\n",
    "So far, we've thought about several factors to trader's transaction patterns.\n",
    "Of course price was the first thing and we got first conclusion of main transaction price.\n",
    "Second was book-feature which is the differences in price and mid-price. And it was clear that trader's main transaction book feature is under 7,000,000 won.\n",
    "Lastly, we thought about transaction time. It didn't seem to be strong correlation to trades even though time is quite important factor in almost every cases.\n",
    "\n",
    "Unfortunately, we couldn't find a big difference between case of sells and purchases with 5 data types.\n",
    "We've just reached that there was a specific intersection of price and book-feature and in this section, trader would buy or sell BTC.\n",
    "\n",
    "\n",
    "As a result, we couldn't find a very obvious and specific transaction patterns with 2018-05-newtrade dataset. Instead of generalized statements, we caught some dealing patterns and a few trend lines.\n",
    "- Correlation between Transaction Counts and Book Feature:\n",
    "Total counts of sells and purchases decreases proportionally since it's over 1,000,000 won. Each one has a downward tendency the same.\n",
    "\n",
    "- Trader has high possibility of purchase around 2,000,000 won. It's the only book-feature section that total counts of purchases is more than one of sells. The others trader tends to sell BTC.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plotting the data\n",
    "\n",
    "First let's make a plot of our data to see how it looks. In order to have a 2D plot, let's ignore the timestamp and mid-price."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Function to help us plot\n",
    "def plot_points(data):\n",
    "    X = np.array(data[['price', 'book_feature']])\n",
    "    y = np.array(data['side'])\n",
    "    purchases = X[np.argwhere(y==0)]\n",
    "    sells = X[np.argwhere(y==1)]\n",
    "    plt.scatter([s[0][0] for s in purchases], [s[0][1] for s in purchases], s = 25, color = 'red', edgecolor = 'k')\n",
    "    plt.scatter([s[0][0] for s in sells], [s[0][1] for s in sells], s = 25, color = 'cyan', edgecolor = 'k')\n",
    "    plt.xlabel('Price')\n",
    "    plt.ylabel('Book Feature')\n",
    "    \n",
    "# Plotting the points    \n",
    "plot_points(data)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Roughly, it looks like the price from 9,820,000 won to 10,000,000 with the book-feature from -500,000 won to 2,000,000 won was dealt, while the ones with high prices didn't, but the data is not as nicely separable as we hoped it would. \n",
    "Maybe it would help to separate the book-feature ranges? Let's make 5 plots, each has 2,000,000 differences."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Separating the book-feature ranges\n",
    "cond1 = data['book_feature'] < 0\n",
    "cond2 = data['book_feature'] > 0\n",
    "cond3 = data['book_feature'] < 4000000\n",
    "cond4 = data['book_feature'] > 4000000\n",
    "cond5 = data['book_feature'] < 8000000\n",
    "cond6 = data['book_feature'] > 8000000\n",
    "cond7 = data['book_feature'] < 12000000\n",
    "cond8 = data['book_feature'] > 12000000\n",
    "\n",
    "data_range1 = data[cond1]\n",
    "data_range2 = data[cond2 & cond3]\n",
    "data_range3 = data[cond4 & cond5]\n",
    "data_range4 = data[cond6 & cond7]\n",
    "data_range5 = data[cond8]\n",
    "\n",
    "# Plotting the graphs\n",
    "plot_points(data_range1)\n",
    "plt.title(\"Book Feature 1(~0)\")\n",
    "plt.show()\n",
    "plot_points(data_range2)\n",
    "plt.title(\"Book Feature 2(0~4,000,000)\")\n",
    "plt.show()\n",
    "plot_points(data_range3)\n",
    "plt.title(\"Book Feature 3(4,000,000~8,000,000)\")\n",
    "plt.show()\n",
    "plot_points(data_range4)\n",
    "plt.title(\"Book Feature 4(8,000,000~12,000,000)\")\n",
    "plt.show()\n",
    "plot_points(data_range5)\n",
    "plt.title(\"Book Feature 5(12,000,000~)\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It seems that the lowest transaction counts at range4, and the next is range3. Most of them are at range1 and range2. \n",
    "And it's common thing that few transactions are at price from 1,000,000 won to 12,000,000 won over all ranges.\n",
    "Let's use the book-feature as one of our inputs. In order to do this, we should one-hot encode it.\n",
    "\n",
    "Before encoding, we should replace book_feature with simple integer and remove unused columns."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Reload data\n",
    "data = pd.read_csv('data/2018-05-newtrade.csv')\n",
    "\n",
    "# Pandas display option for later scaling\n",
    "pd.options.display.float_format='{:.2f}'.format\n",
    "\n",
    "# Remove unnecessary factors\n",
    "data = data.drop('mid_price',1)\n",
    "data = data.drop('timestamp',1)\n",
    "\n",
    "# Replace book-feature price with five range numbers\n",
    "data.loc[cond1, 'book_feature'] = 1\n",
    "data.loc[cond2 & cond3, 'book_feature'] = 2\n",
    "data.loc[cond4 & cond5, 'book_feature'] = 3\n",
    "data.loc[cond6 & cond7, 'book_feature'] = 4\n",
    "data.loc[cond8, 'book_feature'] = 5\n",
    "\n",
    "# Copying book-feature\n",
    "data['book_feature_origin'] = data['book_feature']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## One-hot encoding the book feature\n",
    "We'll use the `get_dummies` function in pandas.\n",
    "Let's do one-hot encoding:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Make dummy variables for rank\n",
    "one_hot_data = pd.concat([data, pd.get_dummies(data['book_feature'], prefix='book_feature')], axis=1)\n",
    "\n",
    "# Drop the previous rank column\n",
    "one_hot_data = one_hot_data.drop('book_feature', axis=1)\n",
    "\n",
    "# Print the first 10 rows of our data\n",
    "one_hot_data[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Scaling the data\n",
    "The next step is to scale the data. We notice that the range for book-feature is 1.0-5.0, whereas the range for price is roughly 9,760,000-10,230,000 which is much larger. This means our data is skewed, and that makes it hard for a neural network to handle. Let's fit our two features into a range of 0-1, by dividing the book-feature by 5.0, and the prices by 10,230,000."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Copying our data\n",
    "processed_data = one_hot_data[:]\n",
    "\n",
    "# Scaling the columns\n",
    "processed_data['price'] = processed_data['price']/10230000\n",
    "processed_data['book_feature_origin'] = processed_data['book_feature_origin']/5.0\n",
    "processed_data[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Splitting the data into Training and Testing\n",
    "In order to test our algorithm, we'll split the data into a Training and a Testing set. The size of the testing set will be 10% of the total data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "sample = np.random.choice(processed_data.index, size=int(len(processed_data)*0.9), replace=False)\n",
    "train_data, test_data = processed_data.iloc[sample], processed_data.drop(sample)\n",
    "\n",
    "print(\"Number of training samples is\", len(train_data))\n",
    "print(\"Number of testing samples is\", len(test_data))\n",
    "print(train_data[:10])\n",
    "print(test_data[:10])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    }
   },
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Number of training samples is 820\nNumber of testing samples is 92\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "              timestamp     price  side   mid_price  book_feature\n1   2018-05-01 01:06:16  10163000     1  10141500.0    -3264355.0\n10  2018-05-01 01:27:22  10153000     1  10147000.0    -2416599.0\n33  2018-05-01 03:15:42  10175000     0  10169000.0     7247598.0\n39  2018-05-01 04:08:35  10160000     1  10144000.0    10058654.0\n46  2018-05-01 04:15:59  10154000     1  10137000.0     3889905.0\n47  2018-05-01 04:20:00  10155000     0  10137000.0     4694330.0\n52  2018-05-01 04:56:41  10179000     0  10161000.0     6163763.0\n57  2018-05-01 06:50:41  10170000     0  10157000.0    -1347888.0\n62  2018-05-01 06:54:09  10161000     1  10151000.0     4052992.0\n80  2018-05-01 07:19:21  10216000     1  10189000.0    17147702.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>timestamp</th>\n      <th>price</th>\n      <th>side</th>\n      <th>mid_price</th>\n      <th>book_feature</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>2018-05-01 01:06:16</td>\n      <td>10163000</td>\n      <td>1</td>\n      <td>10141500.0</td>\n      <td>-3264355.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>2018-05-01 01:27:22</td>\n      <td>10153000</td>\n      <td>1</td>\n      <td>10147000.0</td>\n      <td>-2416599.0</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>2018-05-01 03:15:42</td>\n      <td>10175000</td>\n      <td>0</td>\n      <td>10169000.0</td>\n      <td>7247598.0</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>2018-05-01 04:08:35</td>\n      <td>10160000</td>\n      <td>1</td>\n      <td>10144000.0</td>\n      <td>10058654.0</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>2018-05-01 04:15:59</td>\n      <td>10154000</td>\n      <td>1</td>\n      <td>10137000.0</td>\n      <td>3889905.0</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>2018-05-01 04:20:00</td>\n      <td>10155000</td>\n      <td>0</td>\n      <td>10137000.0</td>\n      <td>4694330.0</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>2018-05-01 04:56:41</td>\n      <td>10179000</td>\n      <td>0</td>\n      <td>10161000.0</td>\n      <td>6163763.0</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>2018-05-01 06:50:41</td>\n      <td>10170000</td>\n      <td>0</td>\n      <td>10157000.0</td>\n      <td>-1347888.0</td>\n    </tr>\n    <tr>\n      <th>62</th>\n      <td>2018-05-01 06:54:09</td>\n      <td>10161000</td>\n      <td>1</td>\n      <td>10151000.0</td>\n      <td>4052992.0</td>\n    </tr>\n    <tr>\n      <th>80</th>\n      <td>2018-05-01 07:19:21</td>\n      <td>10216000</td>\n      <td>1</td>\n      <td>10189000.0</td>\n      <td>17147702.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 82
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Splitting the data into features and targets (labels)\n",
    "Now, as a final step before the training, we'll split the data into features (X) and targets (y).\n",
    "\n",
    "Also, in Keras, we need to one-hot encode the output. We'll do this with the `to_categorical function`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Importing keras\n",
    "import keras\n",
    "\n",
    "# Separate data and one-hot encode the output\n",
    "# Note: We're also turning the data into numpy arrays, in order to train the model in Keras\n",
    "features = np.array(train_data.drop('side', axis=1))\n",
    "targets = np.array(keras.utils.to_categorical(train_data['side'], 2))\n",
    "features_test = np.array(test_data.drop('side', axis=1))\n",
    "targets_test = np.array(keras.utils.to_categorical(test_data['side'], 2))\n",
    "\n",
    "print(features[:10])\n",
    "print(targets[:10])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Defining the model architecture\n",
    "Here's where we use Keras to build our neural network."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0., 1.],\n       [1., 0.],\n       [0., 1.],\n       [1., 0.],\n       [1., 0.],\n       [0., 1.],\n       [1., 0.],\n       [1., 0.],\n       [1., 0.],\n       [0., 1.]], dtype=float32)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 83
    }
   ],
   "source": [
    "# Importing Sequential, Dense, Dropout, etc.\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# Building the model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(7,)))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(.1))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Training the model\n",
    "model.fit(features, targets, epochs=200, batch_size=100, verbose=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Scoring the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Evaluating the model on the training and testing set\n",
    "score = model.evaluate(features, targets)\n",
    "print(\"\\n Training Accuracy:\", score[1])\n",
    "score = model.evaluate(features_test, targets_test)\n",
    "print(\"\\n Testing Accuracy:\", score[1])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}